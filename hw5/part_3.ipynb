{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch MNIST"
      ],
      "metadata": {
        "id": "6s-lmfMe_Ayk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Modules"
      ],
      "metadata": {
        "id": "Pn2VJMlW-6BS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gw0tnCk39sIm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Device and Hyper parameters"
      ],
      "metadata": {
        "id": "vO_Uc5Af_q8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "learning_rate = 0.001\n",
        "epochs = 5\n"
      ],
      "metadata": {
        "id": "q14-WQXt-nar"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the MNIST dataset"
      ],
      "metadata": {
        "id": "XgNcY89__uUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load MNIST dataset\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        root='.', train=True, download=True, transform=transforms.ToTensor()\n",
        "    ),\n",
        "    batch_size=batch_size, shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        root='.', train=False, download=True, transform=transforms.ToTensor()\n",
        "    ),\n",
        "    batch_size=batch_size, shuffle=False\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw9XL58x-rwz",
        "outputId": "2936d2aa-ac2d-4b3c-a825-218b8bcc0b2f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 54029163.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1838732.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 14457019.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4937928.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Definition"
      ],
      "metadata": {
        "id": "V4gVWVir_yUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define neural network model (equivalent to a Keras Dense model)\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 128)  # Input layer\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 64)    # Hidden layer\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(64, 10)     # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)  # Flatten the input\n",
        "        x = self.relu1(self.fc1(x))\n",
        "        x = self.relu2(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = MLP().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "nWuFXCPr-wnv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Training and Testing Functions"
      ],
      "metadata": {
        "id": "V2V_eVPi_4ps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training loop\n",
        "def train(model, train_loader):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, target)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "# Test loop\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    print(f'Accuracy: {100 * correct / total:.2f}%')\n"
      ],
      "metadata": {
        "id": "0-5TdTFY-0qy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "aQpphi-LAECu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run training\n",
        "train(model, train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFOXsNju-3vh",
        "outputId": "287f294f-2e7a-4f2f-f8f8-b6a6cc0cc5f6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.4124\n",
            "Epoch [2/5], Loss: 0.1745\n",
            "Epoch [3/5], Loss: 0.1253\n",
            "Epoch [4/5], Loss: 0.0971\n",
            "Epoch [5/5], Loss: 0.0769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "D_b7kCaEAFnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run testing\n",
        "test(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VxBm2TK_QXt",
        "outputId": "cd6cf65d-ef60-4737-898e-a46e0c00bfec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 97.05%\n"
          ]
        }
      ]
    }
  ]
}